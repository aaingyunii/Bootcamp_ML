{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "112ded0c",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "### ìœ„ìŠ¤ì½˜ì‹  ìœ ë°©ì•” ë°ì´í„°ì…‹\n",
    "- ìœ„ìŠ¤ì½˜ì‹  ëŒ€í•™êµì—ì„œ ì œê³µí•œ ìœ ë°©ì•” ì§„ë‹¨ê²°ê³¼ ë°ì´í„°\n",
    "- Feature: ì¢…ì–‘ ì¸¡ì •ê°’ë“¤\n",
    "    - ëª¨ë“  Featureë“¤ì€ ì—°ì†í˜•(continous)ì´ë‹¤.\n",
    "- target: ì•…ì„±, ì–‘ì„± ì—¬ë¶€\n",
    "- scikit-learnì—ì„œ toy datasetìœ¼ë¡œ ì œê³µí•œë‹¤. \n",
    "    - load_breast_cancer() í•¨ìˆ˜ ì´ìš©<br><br>\n",
    "\n",
    "> 'ìœ„ìŠ¤ì½˜ì‹  ìœ ë°©ì•” ë°ì´í„°ì…‹'ì„ ì´ìš©í•´ Feature Scalingì˜ ë‘ê°€ì§€ ë°©ë²•(Standard Scaling, MinMax Scaling)ì„ ì‹¤í–‰í•˜ê³ \n",
    "ê°ê°ì˜ ë³€í™˜ ë°ì´í„°ì…‹ìœ¼ë¡œ `SVC`ëª¨ë¸ë§ì„ í•˜ê³  `accuracy_score` í™•ì¸í•˜ê¸°.<br><br>\n",
    "    \n",
    "- StandardScalerì™€ MinMax Scalerë¥¼ ì´ìš©í•´ ìœ„ìŠ¤ì½˜ì‹  ìœ ë°©ì•” ë°ì´í„°ì…‹ì˜ Featureë“¤ scaling ì²˜ë¦¬ë¥¼ í•œë‹¤.\n",
    "    - Scaler í•™ìŠµì€ Train setìœ¼ë¡œ ë§Œ í•˜ê³  ê·¸ í•™ìŠµëœ ê²ƒì„ ì´ìš©í•´ Train/Validation/Test setì„ ë³€í™˜í•œë‹¤.\n",
    "- **StandardScaler ë¡œ ë³€í™˜í•œ ê²°ê³¼ë¥¼ ì €ì¥í•  ë³€ìˆ˜**\n",
    "    - X_train_scaled1, X_val_scaled1, X_test_scaled1\n",
    "- **MinMaxScaler ë¡œ ë³€í™˜í•œ ê²°ê³¼ë¥¼ ì €ì¥í•  ë³€ìˆ˜**\n",
    "    - X_train_scaled2, X_val_scaled2, X_test_scaled2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7119def",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((569, 30), (569,))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ë°ì´í„° ë¡œë“œ\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "data = load_breast_cancer()\n",
    "X = data['data']\n",
    "y = data['target']\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bdfa2d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([212, 357], dtype=int64))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1758bdff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['malignant', 'benign'], dtype='<U9')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0: ì•…ì„± , 1: ì–‘ì„±\n",
    "data['target_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "027e0dcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
       "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
       "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
       "       'smoothness error', 'compactness error', 'concavity error',\n",
       "       'concave points error', 'symmetry error',\n",
       "       'fractal dimension error', 'worst radius', 'worst texture',\n",
       "       'worst perimeter', 'worst area', 'worst smoothness',\n",
       "       'worst compactness', 'worst concavity', 'worst concave points',\n",
       "       'worst symmetry', 'worst fractal dimension'], dtype='<U23')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['feature_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0519e197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((364, 30), (91, 30), (114, 30))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train validation test set ë¶„ë¦¬\n",
    "\n",
    "X_tmp, X_test, y_tmp, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=0)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_tmp, y_tmp, \n",
    "                                                  test_size=0.2, \n",
    "                                                  stratify=y_tmp, random_state=0)\n",
    "\n",
    "X_train.shape, X_val.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d44dbaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Scaling\n",
    "# ê°ì²´ ìƒì„±\n",
    "s_scaler = StandardScaler()\n",
    "\n",
    "# í•™ìŠµ ë° ë³€í™˜\n",
    "X_train_scaled1 = s_scaler.fit_transform(X_train)\n",
    "X_val_scaled1 = s_scaler.transform(X_val)\n",
    "X_test_scaled1 = s_scaler.transform(X_test)\n",
    "\n",
    "# ê° feature ë“¤ì˜ mean ì´ 0ì— ê°€ê¹ê²Œ, std ê°€ 1ì— ê°€ê¹ê²Œ ë³€í™˜ë¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95c3d3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MinMax Scaling\n",
    "# ê°ì²´ ìƒì„±\n",
    "mm_scaler = MinMaxScaler()\n",
    "\n",
    "# í•™ìŠµ ë° ë³€í™˜\n",
    "X_train_scaled2 = mm_scaler.fit_transform(X_train)\n",
    "X_val_scaled2 = mm_scaler.transform(X_val)\n",
    "X_test_scaled2 = mm_scaler.transform(X_test)\n",
    "\n",
    "# X_trainì€ min(0) max(1) ê°’ë“¤ë¡œ ë³€í™˜ë˜ì—ˆê³ ,\n",
    "# val, testëŠ” trainì˜ min/max ê¸°ì¤€ìœ¼ë¡œ scalingì´ ì§„í–‰ë˜ì—ˆê¸° ë•Œë¬¸ì—\n",
    "# ì´ˆê³¼ë˜ëŠ” ê°’ì€ 1ë³´ë‹¤ í¬ê²Œ, ë¯¸ë§Œì¸ ê°’ì€ 0ë³´ë‹¤ ì‘ê²Œ, ë³€í™˜ë˜ì—ˆì§€ë§Œ\n",
    "# ê·¸ë¦¬ í° ì°¨ì´ë¥¼ ë³´ì—¬ì£¼ì§€ ì•Šì•„ í•´ë‹¹ ë°ì´í„°ì…‹ì€ MinMax Scalingìœ¼ë¡œë„ ëª¨ë¸ë§ì„ í• ë§Œí•˜ë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08be85b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC ëª¨ë¸ë§, accuracy í‰ê°€ì§€í‘œ\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd6cba6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 0.6263736263736264\n",
      "validation: 0.6263736263736264\n"
     ]
    }
   ],
   "source": [
    "# Scalingì„ ì§„í–‰í•˜ì§€ ì•Šì€ ë°ì´í„°ì…‹ ëª¨ë¸ë§, í…ŒìŠ¤íŠ¸ìš©\n",
    "svm = SVC(random_state=0, C=0.1, gamma=0.1)\n",
    "# í•™ìŠµ\n",
    "svm.fit(X_train, y_train)\n",
    "# ê²€ì¦\n",
    "## ì¶”ë¡ \n",
    "pred_train = svm.predict(X_train)\n",
    "pred_val = svm.predict(X_val)\n",
    "## í‰ê°€ - ì •í™•ë„\n",
    "print(\"train:\", accuracy_score(y_train, pred_train))\n",
    "print(\"validation:\", accuracy_score(y_val, pred_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f8f1352d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 0.9560439560439561\n",
      "validation 0.9340659340659341\n"
     ]
    }
   ],
   "source": [
    "# Standard Scalingì„ í•œ ë°ì´í„°ì…‹ ëª¨ë¸ë§\n",
    "svm = SVC(random_state=0, C=0.1, gamma=0.1)\n",
    "\n",
    "# í•™ìŠµ\n",
    "svm.fit(X_train_scaled1, y_train)\n",
    "\n",
    "## ì¶”ë¡ \n",
    "pred_train1 = svm.predict(X_train_scaled1)\n",
    "pred_val1 = svm.predict(X_val_scaled1)\n",
    "\n",
    "## í‰ê°€ - ì •í™•ë„\n",
    "print(\"train\", accuracy_score(y_train,pred_train1))\n",
    "print(\"validation\", accuracy_score(y_val, pred_val1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d7a6ff2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 0.9175824175824175\n",
      "validation: 0.9010989010989011\n"
     ]
    }
   ],
   "source": [
    "# MinMax Scaling ë°ì´í„°ì…‹ ëª¨ë¸ë§\n",
    "\n",
    "# ëª¨ë¸ ìƒì„±\n",
    "svm = SVC(random_state=0, C=0.1, gamma=0.1)\n",
    "\n",
    "# í•™ìŠµ\n",
    "svm.fit(X_train_scaled2, y_train)\n",
    "\n",
    "# ê²€ì¦\n",
    "## ì¶”ë¡ \n",
    "pred_train2 = svm.predict(X_train_scaled2)\n",
    "pred_val2 = svm.predict(X_val_scaled2)\n",
    "\n",
    "## í‰ê°€ - ì •í™•ë„\n",
    "print(\"train:\", accuracy_score(y_train, pred_train2))\n",
    "print(\"validation:\", accuracy_score(y_val, pred_val2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44b5c01",
   "metadata": {},
   "source": [
    "- ìœ„ì˜ ê²°ê³¼ê°’ì— ë”°ë¼ì„œ ìµœì¢…í‰ê°€ì— ì‚¬ìš©ë  ë°ì´í„°ì…‹ì€<br>ê°€ì¥ ê²°ê³¼ê°€ ì¢‹ì€ 'Standard Scaling' ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•  ê²ƒ\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c3aee1",
   "metadata": {},
   "source": [
    "# TODO adult dataset ëª¨ë¸ë§\n",
    "\n",
    "- ì „ì²˜ë¦¬\n",
    "    - ë²”ì£¼í˜•: one hot encoding\n",
    "    - ì—°ì†í˜•: standard scaling\n",
    "- ëª¨ë¸\n",
    "    - sklearn.linear_model.**LogisticRegression(max_iter=1000, random_state=0)**\n",
    "    - sklearn.svm.**SVC(random_state=0)**\n",
    "- train/test datasetìœ¼ë¡œ ë‚˜ëˆ„ê³  train setìœ¼ë¡œ cross validation í•™ìŠµ ë° ê²€ì¦ì„ í•˜ê³  test setìœ¼ë¡œ ìµœì¢… í‰ê°€ ì§„í–‰"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055db5e3",
   "metadata": {},
   "source": [
    "**ë°ì´í„° í•™ìŠµ-ëª¨ë¸ë§ ìˆœì„œ** :\n",
    "1. import\n",
    "2. data loading\n",
    "3. ê²°ì¸¡ì¹˜ ì²˜ë¦¬\n",
    "4. input, output data ë¶„ë¦¬\n",
    "5. ë²”ì£¼í˜• feature ì „ì²˜ë¦¬\n",
    "6. train test set ë¶„ë¦¬\n",
    "7. ì—°ì†í˜• feature ì „ì²˜ë¦¬\n",
    "8. ëª¨ë¸ë§"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2dc9e0",
   "metadata": {},
   "source": [
    "### ğŸš© ì—°ì†í˜• Feature ì „ì²˜ë¦¬ ì‹œ, `Train, (Validation), Test set` ìœ¼ë¡œ ë¶„í• í•œ í›„ ì§„í–‰í•œë‹¤.\n",
    "> Why? -> Validation ê³¼ Test set ë“¤ì€ ì•ìœ¼ë¡œ ì˜ˆì¸¡í•˜ê²Œ ë  **ìƒˆë¡œìš´ ë°ì´í„°**ì— ëŒ€í•´ ì–´ëŠì •ë„ì˜ ì„±ëŠ¥ì¸ì§€ë¥¼ íŒŒì•…í•˜ê¸° ìœ„í•œ í‰ê°€ë¥¼ í•˜ëŠ” ë°ì´í„°ì…‹ë“¤ì´ë‹¤. ê·¸ëŸ¬ë‚˜ ì´ë“¤ì´ **ê°™ì€ scaleì„ ê°€ì§€ëŠ” ì§€ ë³´ì¥í•  ìˆ˜ ì—†ê¸° ë•Œë¬¸ì—**<br>\n",
    "`ì „ì²´ ë°ì´í„°ì…‹ì„ Scaling`í•˜ê³  Train, Validation, Test set ìœ¼ë¡œ ë‚˜ëˆ„ëŠ” ê²ƒì€ **ëª¨ë¸ì˜ ì„±ëŠ¥ íŒŒì•…ì´ ì–´ë µë‹¤.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "61c8d605",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['age', 'workclass','fnlwgt','education', 'education-num', 'marital-status', 'occupation','relationship', 'race', 'gender','capital-gain','capital-loss', 'hours-per-week','native-country', 'income']\n",
    "\n",
    "# ì›í•«ì¸ì½”ë”©\n",
    "category_columns = ['workclass','education','marital-status', 'occupation','relationship','race','gender','native-country']\n",
    "\n",
    "# Feature Scaling\n",
    "continuous_columns = ['age','fnlwgt', 'education-num','capital-gain','capital-loss','hours-per-week']\n",
    "\n",
    "# ë ˆì´ë¸” ì¸ì½”ë”©\n",
    "target = 'income'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a2bb3918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c4893407",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name = np.array([\"5ë§Œë‹¬ëŸ¬ ì´í•˜\", \"5ë§Œë‹¬ëŸ¬ ì´ˆê³¼\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bc5ca496",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32561, 15)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/adult.data', \n",
    "                   header=None,\n",
    "                   names=cols,\n",
    "                   skipinitialspace=True,\n",
    "                   na_values=\"?\"\n",
    ")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bf5d561f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30162, 15)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ê²°ì¸¡ì¹˜ ì œê±°\n",
    "df.dropna(inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d6a425af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í–‰ì‚­ì œ í›„ index nameì„ ë‹¤ì‹œ ì„¤ì • (0ë¶€í„° 1ì”© ì¦ê°€)\n",
    "df.reset_index(drop=True, inplace = True) ## index ì»¬ëŸ¼ì„ ë§Œë“¤ì§€ ë§ê³  ë¹¼ì„œ í–‰ ì¸ë±ìŠ¤ë¡œ ëƒ…ë‘ê¸°\n",
    "# ì›ë˜ indexë¥¼ ì œê±°í•˜ê³  ìë™ì¦ê°€ ì •ìˆ˜ indexë¡œ ë³€ê²½\n",
    "\n",
    "## í˜„ì¬ ë°ì´í„°ì…‹ì€ reset_indexê°€ í•„ìš”ì—†ìœ¼ë‚˜\n",
    "## ê³ ìœ  ID ê°’ì„ ê°€ì§€ëŠ” ë°ì´í„°ì…‹ì˜ ê²½ìš° indexë¥¼ ì¬ì¡°ì •í•  í•„ìš”ê°€ ìˆì„ ìˆ˜ ìˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a8c98400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 1, 1, 1])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X,yë¥¼ ë¶„ë¦¬\n",
    "## y : ë ˆì´ë¸” ì¸ì½”ë”©\n",
    "y = LabelEncoder().fit_transform(df[target])\n",
    "y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "975abfcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30162, 98)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X ì¤‘ ë²”ì£¼í˜• íƒ€ì… featureì— ëŒ€í•´ One-Hot Encoding ì²˜ë¦¬\n",
    "ohe = OneHotEncoder(sparse_output=False) # handle_unknown=\"ignore\" : ëª¨ë¥´ëŠ” ë°ì´í„°ì— ëŒ€í•´ 0ìœ¼ë¡œ ìë™ ì²˜ë¦¬\n",
    "                                        # defaultëŠ” \"error\" : ëª¨ë¥´ëŠ” ë°ì´í„°ì— ëŒ€í•´ ì—ëŸ¬ ë°œìƒ\n",
    "ohe_tmp = ohe.fit_transform(df[category_columns])\n",
    "ohe_tmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b2a0498e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30162, 104)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ì›í•«ì¸ì½”ë”© ê²°ê³¼ + ì—°ì†í˜• ì»¬ëŸ¼ê°’ = Dataset\n",
    "X = np.concatenate([ohe_tmp,df[continuous_columns].values], axis=1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b0bde0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ìœ„ì˜ ê³¼ì •ì—ì„œ \n",
    "### (ì „ì²˜ë¦¬ ì™„ë£Œí•œ) ë²”ì£¼í˜• ë°ì´í„° + (ê·¸ëŒ€ë¡œì¸) ì—°ì†í˜• ë°ì´í„° => 1ì°¨ DataSet ì™„ì„±ì´ ë¨.\n",
    "\n",
    "### ì´í›„ train, test ì…‹ìœ¼ë¡œ ë¶„ë¦¬í•œ ì´í›„ \n",
    "### ì—°ì†í˜• ë°ì´í„° ì „ì²˜ë¦¬ë¥¼ í•˜ê³  ìµœì¢… ëª¨ë¸ë§ì„ í•œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "253a7027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((22621, 104), (7541, 104))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train, test set ë¶„ë¦¬\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,\n",
    "                                                   stratify=y,\n",
    "                                                   random_state=0)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3deff7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Standard Scaling\n",
    "####### Train set í•™ìŠµ, Train/Test ë³€í™˜\n",
    "s_scale = StandardScaler()\n",
    "X_train_scaled = s_scale.fit_transform(X_train)\n",
    "X_test_scaled = s_scale.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "84e2b564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëª¨ë¸ë§ - Cross Validation\n",
    "lr = LogisticRegression(max_iter=1000,random_state=0)\n",
    "result_lr=cross_val_score(lr,\n",
    "                         X_train_scaled, # feature(X, input data)\n",
    "                         y_train, # target(y, output data, label)\n",
    "                         scoring = \"accuracy\", # í‰ê°€ì§€í‘œ\n",
    "                         cv=5, # fold ê°œìˆ˜\n",
    "                         n_jobs=-1 # ë³‘ë ¬ ì²˜ë¦¬ì‹œ ì‚¬ìš©í•  cpu í”„ë¡œì„¸ì„œ ê°œìˆ˜, -1: ì „ë¶€ë‹¤ ì‚¬ìš©\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e8a07802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8490779977626997\n"
     ]
    }
   ],
   "source": [
    "print(result_lr.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "578d781e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëª¨ë¸ë§ - SVC\n",
    "svm = SVC(random_state=0)\n",
    "result_svm=cross_val_score(svm,\n",
    "                         X_train_scaled, # feature(X, input data)\n",
    "                         y_train, # target(y, output data, label)\n",
    "                         scoring = \"accuracy\", # í‰ê°€ì§€í‘œ\n",
    "                         cv=5, # fold ê°œìˆ˜\n",
    "                         n_jobs=-1 # ë³‘ë ¬ ì²˜ë¦¬ì‹œ ì‚¬ìš©í•  cpu í”„ë¡œì„¸ì„œ ê°œìˆ˜, -1: ì „ë¶€ë‹¤ ì‚¬ìš©\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6524ce86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8448341320202628\n"
     ]
    }
   ],
   "source": [
    "print(result_svm.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0b8ee8aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000, random_state=0)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## LogisticRegression ì„±ëŠ¥ì´ ë” ì¢‹ìŒ => ì¬í•™ìŠµ\n",
    "best_model = LogisticRegression(max_iter=1000, random_state=0)\n",
    "best_model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2cc017e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8456438138177961"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## ìµœì¢… í‰ê°€\n",
    "\n",
    "pred_test = best_model.predict(X_test_scaled)\n",
    "accuracy_score(y_test, pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cfd42b40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['5ë§Œë‹¬ëŸ¬ ì´ˆê³¼', '5ë§Œë‹¬ëŸ¬ ì´í•˜', '5ë§Œë‹¬ëŸ¬ ì´í•˜', ..., '5ë§Œë‹¬ëŸ¬ ì´í•˜', '5ë§Œë‹¬ëŸ¬ ì´ˆê³¼',\n",
       "       '5ë§Œë‹¬ëŸ¬ ì´í•˜'], dtype='<U7')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_name[pred_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ceda372",
   "metadata": {},
   "source": [
    "# ëª¨ë¸ ì €ì¥\n",
    "### `pickle` ëª¨ë“ˆ í™œìš©!\n",
    "\n",
    "> ## pickle ëª¨ë“ˆì‚¬ìš©\n",
    "> - ê°ì²´ íŒŒì¼ ì…ì¶œë ¥ì„ ìœ„í•œ íŒŒì´ì¬ ëª¨ë“ˆ\n",
    "> - open() ì‹œ **binary mode**ë¡œ ì„¤ì •í•œë‹¤.\n",
    "> - ì €ì¥ì‹œ íŒŒì¼ í™•ì¥ìëŠ” ë³´í†µ `pkl` ì´ë‚˜ `pickle` ë¡œ í•œë‹¤.\n",
    "> - ex)\n",
    "> ```python\n",
    "> fw = open(\"data.pkl\", \"wb\") # ê°ì²´ë¥¼ pickleì— ì €ì¥í•˜ê¸° ìœ„í•œ output stream ìƒì„±\n",
    "> fr = open(\"data.pkl\", \"rb\") # íŒŒì¼ì— ì €ì¥ëœ ê°ì²´ë¥¼ ì½ì–´ì˜¤ê¸° ìœ„í•œ input stream ìƒì„±\n",
    "> ```\n",
    "> - **ë©”ì†Œë“œ**\n",
    ">     - dump(ì €ì¥í•  ê°ì²´, fw) : ì¶œë ¥\n",
    ">     - load(fr): ì…ë ¥ - ì½ì€ ê°ì²´ë¥¼ ë°˜í™˜í•œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d8d64d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "save_root = 'adult_data_model'\n",
    "\n",
    "ohe_path = os.path.join(save_root, 'ohe.pkl')\n",
    "scaler_path = os.path.join(save_root, 'scaler.pkl')\n",
    "model_path = os.path.join(save_root, 'model.pkl')\n",
    "\n",
    "os.makedirs(save_root, exist_ok=True) # save_root ë””ë ‰í† ë¦¬ë¥¼ ìƒì„±\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7a5a15ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0b99e386",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### ì €ì¥\n",
    "# OheHotEcoderì €ì¥\n",
    "with open(ohe_path, \"wb\") as fw1:\n",
    "    pickle.dump(ohe, fw1) # (ì €ì¥í•  ê°ì²´-ê°’, ì¶œë ¥stream-wb)\n",
    "\n",
    "# StandardScaler ì €ì¥\n",
    "with open(scaler_path, \"wb\") as fw2:\n",
    "    pickle.dump(s_scale, fw2)\n",
    "    \n",
    "# ëª¨ë¸ ì €ì¥\n",
    "with open(model_path, \"wb\") as fw3:\n",
    "    pickle.dump(best_model, fw3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "25287aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### ë¡œë”©\n",
    "import pickle\n",
    "# ëª¨ë¸ ë¡œë”©\n",
    "with open(model_path, 'rb') as fr1:\n",
    "    save_model = pickle.load(fr1) # ì½ì–´ë“œë¦´ í”¼í´íŒŒì¼ê³¼ ì—°ê²°ëœ input stream\n",
    "    \n",
    "# OheHotEcoder loading\n",
    "with open(ohe_path, 'rb') as fr2:\n",
    "    save_ohe = pickle.load(fr2)\n",
    "    \n",
    "# scaler loading\n",
    "with open(scaler_path, 'rb') as fr3:\n",
    "    save_scaler = pickle.load(fr3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "efcce123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8456438138177961"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "pred_test10 = save_model.predict(X_test_scaled)\n",
    "accuracy_score(y_test, pred_test10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "23c1fa94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass  fnlwgt  education  education-num  \\\n",
       "0   39         State-gov   77516  Bachelors             13   \n",
       "1   50  Self-emp-not-inc   83311  Bachelors             13   \n",
       "2   38           Private  215646    HS-grad              9   \n",
       "3   53           Private  234721       11th              7   \n",
       "4   28           Private  338409  Bachelors             13   \n",
       "\n",
       "       marital-status         occupation   relationship   race  gender  \\\n",
       "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
       "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
       "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
       "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
       "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week native-country income  \n",
       "0          2174             0              40  United-States  <=50K  \n",
       "1             0             0              13  United-States  <=50K  \n",
       "2             0             0              40  United-States  <=50K  \n",
       "3             0             0              40  United-States  <=50K  \n",
       "4             0             0              40           Cuba  <=50K  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ìƒˆë¡œìš´ ë°ì´í„° ì¶”ë¡ \n",
    "new_data = df.iloc[:5]\n",
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "aa074fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì „ì²˜ë¦¬\n",
    "### OneHotEncoding ì´í›„ Standard Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e8c24835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 98)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encoding\n",
    "tmp = save_ohe.transform(new_data[category_columns])\n",
    "tmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "746b2dfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 104)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ohe + ì—°ì†í˜•\n",
    "tmp2 = np.concatenate([tmp,new_data[continuous_columns].values], axis=1)\n",
    "tmp2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "22f6da8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 104)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scaling\n",
    "new_X = save_scaler.transform(tmp2)\n",
    "new_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7db949c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_pred = save_model.predict(new_X)\n",
    "new_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5c919167",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['5ë§Œë‹¬ëŸ¬ ì´í•˜', '5ë§Œë‹¬ëŸ¬ ì´í•˜', '5ë§Œë‹¬ëŸ¬ ì´í•˜', '5ë§Œë‹¬ëŸ¬ ì´í•˜', '5ë§Œë‹¬ëŸ¬ ì´ˆê³¼'], dtype='<U7')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_name[new_pred]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
