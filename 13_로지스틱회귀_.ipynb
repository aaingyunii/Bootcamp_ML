{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 로지스틱 회귀 (LogisticRegression)\n",
    "- 선형회귀 알고리즘을 이용한 이진 분류 모델\n",
    "- Sample이 특정 클래스에 속할 확률을 추정한다.    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## 확률 추정\n",
    "- 입력 특성(Feature)에 가중치 합을 계산한 값(선형회귀)을 로지스틱 함수를 적용해 확률을 계산한다.\n",
    "\n",
    "\n",
    "$$\n",
    "\\hat{p} = \\sigma \\left( \\mathbf{w}^{T} \\cdot \\mathbf{X} + \\mathbf{b} \\right)\\\\\n",
    "\\hat{p}:\\: positive의\\,확률,\\quad \\sigma():\\:logistic\\,함수,\\quad \\mathbf{w}:\\:weight,\\quad \\mathbf{X}:\\:input feature,\\quad \\mathbf{b}:\\:bias\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### 로지스틱 함수\n",
    "- 0과 1사이의 실수를 반환한다.\n",
    "- S 자 형태의 결과를 내는 **시그모이드 함수(sigmoid function)** 이다.\n",
    "\n",
    "$$\n",
    "\\sigma(x) = \\frac{1}{1 + \\mathbf{e}^{-x}}\n",
    "$$\n",
    "\n",
    "- 샘플 **x**가 양성에 속할 확률\n",
    "\n",
    "$$\n",
    "\\hat{y} = \\begin{cases} 0\\quad\\hat{p}<0.5\\\\1\\quad\\hat{p}\\geqq0.5 \\end{cases}\n",
    "$$\n",
    "\n",
    "> 결과가 S자 형태를 나타내는 함수를 sigmoid 함수라고 하는데 그 대표적인 함수가 Logistic 함수이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T07:33:57.095219Z",
     "start_time": "2021-10-29T07:33:56.892076Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### logistic 함수 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-09T07:43:24.568876Z",
     "start_time": "2023-02-09T07:43:24.019779Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def logistic_func(X):\n",
    "    return 1 / (1 + np.exp(-X))  \n",
    "\n",
    "X = np.linspace(-10, 10, 1000) \n",
    "y = logistic_func(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.min(), y.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-09T07:51:38.981146Z",
     "start_time": "2023-02-09T07:51:38.798369Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13, 6))\n",
    "\n",
    "plt.plot(X, y, color='b', linewidth=2)\n",
    "\n",
    "plt.axhline(y=0.5, color='r', linestyle=':')\n",
    "# plt.axvline(x=5, color='b', linestyle=':')\n",
    "\n",
    "plt.ylim(-0.15, 1.15)\n",
    "plt.yticks(np.arange(-0.1,1.2,0.1))\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.spines['left'].set_position(\"center\")\n",
    "ax.spines['bottom'].set_position(('data', 0.0))\n",
    "# ax.spines['bottom'].set_color('blue')\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-09T07:53:40.917356Z",
     "start_time": "2023-02-09T07:53:40.901532Z"
    }
   },
   "outputs": [],
   "source": [
    "np.min(y), np.max(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## LogisticRegression의 손실 함수(Loss Function)\n",
    "- **Log loss**\n",
    "    - 모델이 예측한 정답의 확률에 대해 log를 취해 손실값을 구한다.\n",
    "        - 확률이 틀리면 틀릴 수록 손실값을 크게 만들기 위해서 log를 취한다.\n",
    "        $$\n",
    "        \\log{\\left(모델이\\,예측한\\,정답에\\,대한\\,확률\\right)}\n",
    "        $$        \n",
    "        \n",
    "    - 다중분류 또는 이진분류에 따라 log loss를 만드는 공식이 다르다.\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- **Cross Entropy**\n",
    "    - 다중분류에 대한 log loss 공식\n",
    "    - target을 one hot vector로 만들고 클래스 index 모델이 그 클래스에 대해 추론한 확률의 로그값을 곱한다. \n",
    "    $$\n",
    "    L(\\mathbf{W}) = - \\frac{1}{m}\\sum_{i=1}^{m}\\sum_{j=1}^{n}y_{ij}\\log(p(y_{ij}))\n",
    "    $$\n",
    "\n",
    "- i: 몇번째 데이터인지 index\n",
    "- m: 데이터 개수\n",
    "- j: 몇번째 class index인지.\n",
    "- n: class(범주값)의 개수\n",
    "- y: 정답\n",
    "- $p(y_{ij})$: 모델이 추정한 값\n",
    "\n",
    "    \n",
    "    |class|0|1|2|3|\n",
    "    |-|-|-|-|-|\n",
    "    |정답|0|**1**|0|0|\n",
    "    |추정확률|0.1|0.7|0.1|0.1|\n",
    "    \n",
    "    `0*log(0.1) + 1*log(0.7) + 0*log(0.1) + 0*log(0.1) => log(0.7)`\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- **Binary Cross Entropy**\n",
    "    - 이진분류 추론 결과에 대한 cross entropy 계산\n",
    "        - Logistic함수은 positive(1)의 확률만 추출하므로 정답이 0일때, 1일때 계산하는 것이 다르다. 그것을 하나의 공식으로 정의한 것이 binary cross entropy이다.\n",
    "        - 아래 공식에서 정답이 1일 경우는 앞의 것이 0일 경우 뒤의 항으로 계산한다.\n",
    "$$\n",
    "L(\\mathbf{W}) = - \\frac{1}{m} \\sum_{i=1}^{m}{\\left[ y_{i} \\log{\\left( \\hat{p}_i \\right)} + \\left( 1 - y_i \\right) \\log{\\left( 1 - \\hat{p}_i \\right)} \\right]}\\\\\n",
    "y:\\:실제값(정답),\\quad\\hat{p}:\\:예측확률(양성확률)\n",
    "$$\n",
    "\n",
    "- y(실제값) 이 1인 경우 $y_{i}\\log{\\left(\\hat{p}_i\\right)}$ 이 손실을 계산\n",
    "- y가 0인 경우 $\\left( 1 - y_i \\right) \\log{\\left( 1 - \\hat{p}_i \\right)}$이 손실을 계산\n",
    "\n",
    "> - **Loss Function**\n",
    ">   - 모델이 예측한 값과 정답간의 차이(오차, loss)를 구하는 함수.\n",
    ">   - 모델의 파라미터를 최적화할 때 loss를 최소화하는 것을 목적으로 한다.\n",
    "> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# 모델이 추정한 정답 확률\n",
    "print(\"완벽 정답:\", np.log(1.0))\n",
    "print(\"완벽 틀린:\", -np.log(0.00000000000000000000000001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.linspace(0.0000000000000001, 1, 1000)\n",
    "y = -np.log(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(X, y)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-np.log(0.51), -np.log(0.7), -np.log(0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-np.log(0.49), -np.log(0.00000000000000000000000000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 최적화 \n",
    "\n",
    "### 최적화란\n",
    "- 모델이 예측한 결과와 정답간의 차이(오차)를 가장 적게 만드는 Parameter를 찾는 과정을 최적화라고 한다.\n",
    "- 모델의 예측값과 실제 값의 차이를 계산하는 함수를 만들고 그 값이 최소가 되는 지점을 찾는 작업을 한다.\n",
    "\n",
    "### 목적함수(Object Function), 손실함수(Loss Function), 비용함수(Cost Function), 오차함수(Error Function)\n",
    "- 모델의 예측한 값과 실제값 사이의 차이를 정의하는 함수로 모델이 학습할 때 사용된다.\n",
    "- 이 함수의 반환값(Loss)을 최소화 하는 파라미터을 찾는 것이 최적화의 목적\n",
    "- 해결하려는 문제에 맞춰 Loss 함수를 정의한다.\n",
    "    - Classification(분류)의 경우 cross entropy(log loss)를 사용한다.\n",
    "    - Regression(회귀)의 경우 MSE(Mean Squared Error)를 사용한다.\n",
    "\n",
    "### LogisticRegression의 최적화\n",
    "- 분류 문제이므로 Cross entropy(Log loss함수)를 손실함수로 사용한다.\n",
    "- Cross entropy는 loss의 최소값으로 하는 parameter 찾는 방정식이 없기 때문에 **LogisticRegression은 경사하강법을 이용해 최적화를 진행한다.**\n",
    "- 로그 손실을 $\\mathbf{W}$로 미분하면 다음과 같다.\n",
    "    - 아래 도함수로 기울기를 구해 기울기가 0이 될 때 까지 W(가중치)들을 update한다.\n",
    "$$\n",
    "\\frac{\\partial}{\\partial w_j}L(W) = \\frac{1}{m} \\sum_{i=1}^{m}{\\left( \\sigma \\left( \\mathbf{W}^{T} \\cdot \\mathbf{x}_i \\right) - \\mathbf{y}_i \\right)} x_{ij}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## LogisticRegression 주요 하이퍼파라미터\n",
    "- penalty: 과적합을 줄이기 위한 규제방식\n",
    "    - 'l1', 'l2'(기본값), 'elasticnet', 'none' \n",
    "- C: 규제강도(기본값 1) - 작을 수록 규제가 강하다(단순).\n",
    "- max_iter(기본값 100) : 경사하강법 반복횟수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-06T08:38:26.792697Z",
     "start_time": "2023-07-06T08:38:23.319099Z"
    }
   },
   "outputs": [],
   "source": [
    "from dataset import get_breast_cancer_dataset\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from metrics import print_metrics_classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "##### 데이터 전처리\n",
    "- LogisticRegression은 선형회귀 기반의 알고리즘이므로 연속형 Feature는 Feature scaling, 범주형 Feature는 One hot encoding 처리를 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-06T08:38:27.960828Z",
     "start_time": "2023-07-06T08:38:27.902130Z"
    }
   },
   "outputs": [],
   "source": [
    "(X_train, X_test, y_train, y_test), feature_names = get_breast_cancer_dataset(scaling=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-06T08:38:28.287621Z",
     "start_time": "2023-07-06T08:38:28.207774Z"
    }
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression(random_state=0)\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-06T08:38:28.548391Z",
     "start_time": "2023-07-06T08:38:28.527288Z"
    }
   },
   "outputs": [],
   "source": [
    "lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-06T08:38:29.369025Z",
     "start_time": "2023-07-06T08:38:29.352262Z"
    }
   },
   "outputs": [],
   "source": [
    "lr.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-06T08:38:30.666074Z",
     "start_time": "2023-07-06T08:38:30.646875Z"
    }
   },
   "outputs": [],
   "source": [
    "pred_train = lr.predict(X_train)\n",
    "pred_test = lr.predict(X_test)\n",
    "pred_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-06T08:38:31.311038Z",
     "start_time": "2023-07-06T08:38:31.302598Z"
    }
   },
   "outputs": [],
   "source": [
    "proba_train = lr.predict_proba(X_train)\n",
    "proba_test = lr.predict_proba(X_test)\n",
    "proba_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-06T08:38:31.871768Z",
     "start_time": "2023-07-06T08:38:31.838013Z"
    }
   },
   "outputs": [],
   "source": [
    "print_metrics_classification(y_train, pred_train, proba_train[:, 1], \"train set\")\n",
    "print_metrics_classification(y_test, pred_test, proba_test[:, 1], \"test set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-06T08:38:36.384623Z",
     "start_time": "2023-07-06T08:38:32.407336Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\n",
    "    'penalty':['l1', 'l2'], #l1: Lasso, l2: Ridge, None: Linear Regression\n",
    "    'C':[0.01, 0.1, 1, 5, 10], # 작을수록 강한 규제(overfitting: 작은값으로 변경.)\n",
    "}\n",
    "# solver: 최적화 알고리즘 -> 경사하강법을 개선한 알고리즘.\n",
    "gs = GridSearchCV(LogisticRegression(random_state=0, solver='liblinear'), \n",
    "                  params, \n",
    "                  scoring='accuracy', \n",
    "                  cv=4, \n",
    "                  n_jobs=-1)\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-06T08:38:38.672647Z",
     "start_time": "2023-07-06T08:38:38.662052Z"
    }
   },
   "outputs": [],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-06T08:38:39.311982Z",
     "start_time": "2023-07-06T08:38:39.296512Z"
    }
   },
   "outputs": [],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-06T08:38:40.049319Z",
     "start_time": "2023-07-06T08:38:39.998730Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "result = pd.DataFrame(gs.cv_results_)\n",
    "result.sort_values('rank_test_score').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
